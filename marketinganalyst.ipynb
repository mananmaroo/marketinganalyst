{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install serpapi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OTpDtjDevd-G",
        "outputId": "a80728ed-d798-42cc-bba5-447182a4c8bc"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting serpapi\n",
            "  Downloading serpapi-0.1.5-py2.py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from serpapi) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->serpapi) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->serpapi) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->serpapi) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->serpapi) (2024.8.30)\n",
            "Downloading serpapi-0.1.5-py2.py3-none-any.whl (10 kB)\n",
            "Installing collected packages: serpapi\n",
            "Successfully installed serpapi-0.1.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kTvJnM0vxHTM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "import time\n",
        "from urllib.parse import urlparse\n",
        "\n",
        "def search_business_links(business_name, business_type=\"general\"):\n",
        "    \"\"\"Searches for business links based on name and type.\"\"\"\n",
        "    api_key = \"673154847cda478a5456744c\"\n",
        "    base_url = \"https://api.scrapingdog.com/google\"\n",
        "    all_links = []\n",
        "    seen_domains = set()\n",
        "    search_queries = [f\"{business_name} {suffix}\" for suffix in\n",
        "                      [\"\", \"reviews\", f\"{business_type}\",\n",
        "                       \"food\" if business_type == \"restaurant\" else \"services\",\n",
        "                       \"accommodations\" if business_type == \"hotel\" else \"company\"]]\n",
        "\n",
        "    for query in search_queries:\n",
        "        for page in range(1, 10):\n",
        "            params = {\n",
        "                \"api_key\": api_key,\n",
        "                \"query\": query,\n",
        "                \"num\": 50,\n",
        "                \"country\": \"in\",\n",
        "                \"start\": (page - 1) * 50\n",
        "            }\n",
        "            response = requests.get(base_url, params=params)\n",
        "            if response.status_code == 200:\n",
        "                for result in response.json().get(\"organic_results\", []):\n",
        "                    link = result.get(\"link\")\n",
        "                    if link and not any(domain in link for domain in [\"facebook.com\", \"instagram.com\", \"twitter.com\", \"/aclk?\"]):\n",
        "                        domain = urlparse(link).netloc\n",
        "                        if domain not in seen_domains:\n",
        "                            all_links.append(link)\n",
        "                            seen_domains.add(domain)\n",
        "            else:\n",
        "                print(f\"Request failed for query '{query}' with status code: {response.status_code}\")\n",
        "            time.sleep(1)  # Be respectful of the API rate limits\n",
        "\n",
        "    return all_links\n",
        "\n",
        "def scrape_reviews(url):\n",
        "    headers = {\"User-Agent\": \"Mozilla/5.0\"}  # Customize User-Agent if needed\n",
        "    response = requests.get(url, headers=headers)\n",
        "    if response.status_code != 200:\n",
        "        return f\"Failed to retrieve the page. Status code: {response.status_code}\"\n",
        "\n",
        "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "    reviews = [element.get_text(strip=True)\n",
        "               for element in soup.find_all('div', class_='review-container')]  # Adjust class if needed\n",
        "    return reviews\n",
        "\n",
        "def get_business_reviews(business_name, business_type=\"general\"):\n",
        "    links = search_business_links(business_name, business_type)\n",
        "    all_reviews = {}\n",
        "    for link in links:\n",
        "        print(f\"{link}\")\n",
        "        try:\n",
        "            all_reviews[link] = scrape_reviews(link)\n",
        "        except Exception as e:\n",
        "            all_reviews[link] = f\"Error occurred: {str(e)}\"\n",
        "    return all_reviews\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    business_name = input(\"Enter the business name: \")\n",
        "    business_type = input(\"Enter business type (hotel, restaurant, or general): \").lower()\n",
        "    reviews_data = get_business_reviews(business_name, business_type)\n",
        "\n",
        "    with open(f\"{business_name}_reviews.txt\", \"w\", encoding=\"utf-8\") as file:\n",
        "        file.write(f\"# {business_name} Reviews\\n\\n\")\n",
        "        for link, reviews in reviews_data.items():\n",
        "            file.write(f\"## Reviews from {link}:\\n\")\n",
        "            if isinstance(reviews, list):\n",
        "                file.write(\"\\n\".join(f\"- {review}\" for review in reviews) + \"\\n\")  # Use join for efficiency\n",
        "            else:\n",
        "                file.write(f\"{reviews}\\n\")\n",
        "            file.write(\"\\n\")\n",
        "\n",
        "    print(f\"Reviews saved to {business_name}_reviews.txt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "id": "5tgCzITxwof9",
        "outputId": "daa53ff2-dabc-4ea3-ea4a-7d2414fa59cf"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the business name: taro udaipur\n",
            "Enter business type (hotel, restaurant, or general): restaurant\n",
            "Request failed for query 'taro udaipur ' with status code: 429\n",
            "Request failed for query 'taro udaipur ' with status code: 429\n",
            "Request failed for query 'taro udaipur ' with status code: 429\n",
            "Request failed for query 'taro udaipur ' with status code: 429\n",
            "Request failed for query 'taro udaipur ' with status code: 429\n",
            "Request failed for query 'taro udaipur reviews' with status code: 429\n",
            "Request failed for query 'taro udaipur reviews' with status code: 429\n",
            "Request failed for query 'taro udaipur reviews' with status code: 429\n",
            "Request failed for query 'taro udaipur reviews' with status code: 429\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-a1cfcae75d30>\u001b[0m in \u001b[0;36m<cell line: 64>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0mbusiness_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Enter the business name: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0mbusiness_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Enter business type (hotel, restaurant, or general): \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0mreviews_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_business_reviews\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbusiness_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbusiness_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{business_name}_reviews.txt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-a1cfcae75d30>\u001b[0m in \u001b[0;36mget_business_reviews\u001b[0;34m(business_name, business_type)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_business_reviews\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbusiness_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbusiness_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"general\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     \u001b[0mlinks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msearch_business_links\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbusiness_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbusiness_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m     \u001b[0mall_reviews\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlink\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlinks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-a1cfcae75d30>\u001b[0m in \u001b[0;36msearch_business_links\u001b[0;34m(business_name, business_type)\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Request failed for query '{query}' with status code: {response.status_code}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Be respectful of the API rate limits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mall_links\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ilBcOPd5xIrM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
